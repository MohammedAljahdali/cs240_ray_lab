{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c7aaf5-63a0-4bb8-bc92-64bf42c9341e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"ray[default]\"\n",
    "!pip install scikit-learn==1.3.1\n",
    "!pip install -U ipywidgets\n",
    "!pip install matplotlib==3.8\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82bbbd-6ec0-476a-9aac-8477e7608e39",
   "metadata": {},
   "source": [
    "# Scaling and Distributing Tasks with Ray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73602284-5e0c-44a9-859b-c0f17981e64a",
   "metadata": {},
   "source": [
    "Welcome to this interactive notebook! Here, we will explore the challenges associated with hyperparameter tuning for ML models and see how we can simplify and scale this process using Ray. By the end, you will have a clear understanding of how to leverage distributed computing for such tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ddc7a1-9261-48e1-a00e-56e74278b30f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset & Model Setup\n",
    "\n",
    "Let's begin by setting up our environment. We'll use the digits dataset from Scikit-learn and aim to classify the hand-written digits using an SVM (Support Vector Machine). SVMs have several hyperparameters that can significantly influence their performance, making them an ideal candidate for our tuning exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223fd4a-4c6e-4dfd-8658-b1f11d154b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "data = load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualize the dataset\n",
    "plt.imshow(X[0].reshape(8, 8), cmap='gray')\n",
    "plt.title(f\"Label: {y[0]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e2ecb-5fef-400b-b010-bb47bbd23df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e7f10-df14-4741-a55d-34107e2ce93f",
   "metadata": {},
   "source": [
    "# Manual Hyperparameter Tuning\n",
    "Hyperparameter tuning involves training my_trainple models with different hyperparameter values to find the best combination. Let's manually loop over a range of the hyperparameter C for our SVM and see how the performance varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350ec5e-0dce-4e3a-b401-57db575d4ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "Cs = [0.01, 0.025, 0.05, 0.1, 1]\n",
    "\n",
    "for C in Cs:\n",
    "    clf = SVC(C=C, )\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "plt.plot(Cs, accuracies, '-o')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Performance vs. C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a81638-ef28-4c7a-ba0d-a55102d7b85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "Cs = [0.01, 0.025, 0.05, 0.1, 1]\n",
    "\n",
    "for C in Cs:\n",
    "    clf = SVC(C=C)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "plt.plot(Cs, accuracies, '-o')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Performance vs. C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f42613-c53f-446c-b09b-135822849936",
   "metadata": {},
   "source": [
    "## More parameters to tune.\n",
    "There other parameters that we can tune in SVM model, you can read more about them [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) in the scikit learn docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64a3bb-2db5-4700-ba07-58cb543109f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.01, 0.025, 0.05, 0.1, 1] \n",
    "gamma_values = [0.1, 1, 'scale', 'auto']\n",
    "kernel_values = ['rbf', 'poly']\n",
    "\n",
    "for C in Cs:\n",
    "    for gamma in gamma_values:\n",
    "        for kernel in kernel_values:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215987b-5998-4782-b6b2-21001b0d4ec8",
   "metadata": {},
   "source": [
    "We will have `len(gamma_values) * len(kernel_values) * len(Cs)` training tasks to do, which is a lot! **So let's scale the tasks using ray**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4433ded5-c0af-4f75-b9fd-6fcd34fd8432",
   "metadata": {},
   "source": [
    "# Scale Hyperparameter Tuning with Ray\n",
    "**TODO: rewrite the training code above as a Ray remote function that takes the chosen hpyerparameters as an input**\n",
    "```\n",
    "clf = SVC(C=C)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracies.append(accuracy_score(y_test, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765d771-a817-4dfa-b16d-db71fe19cf6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee136160-aed6-4e22-87dd-6384221444b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Write a ray function that does the training given the hyperparameters\n",
    "@ray.remote\n",
    "def training_task(X_train, X_test, y_train, y_test, C, gamma, kernel):\n",
    "    clf = SVC(C=C, gamma=gamma, kernel=kernel)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c285be0-0f21-409d-824a-2f6b994b200c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "address = \"ray://3.79.116.251:10001\" # None # Replace the address with the cluster address\n",
    "ray.init(address, ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c2363-896a-4ddf-a38b-5f31872b7d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ref_to_params: {str: tuple} = {}\n",
    "tasks = []\n",
    "for C in Cs:\n",
    "    for gamma in gamma_values:\n",
    "        for kernel in kernel_values:\n",
    "            # TODO: Queue the tasks\n",
    "            task_ref = training_task.remote(X_train, X_test, y_train, y_test, C=C, gamma=gamma, kernel=kernel)\n",
    "            ref_to_params[task_ref] = (C, gamma, kernel)\n",
    "            tasks.append(task_ref)\n",
    "        \n",
    "params_to_accuracy = {}        \n",
    "while tasks:\n",
    "    done_task_ref, tasks = ray.wait(tasks)\n",
    "    done_task_ref = done_task_ref[0]\n",
    "    accuracy = ray.get(done_task_ref)\n",
    "    \n",
    "    params = ref_to_params[done_task_ref]\n",
    "    params_to_accuracy[params] = accuracy\n",
    "    \n",
    "    # print(f\"Task with params {params} is completed, accuarcy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1c782-e0de-48ab-a142-811c24f8f7c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scatter_plot_hyperparameters(params_to_accuracy, hyperparam_names):\n",
    "    # Assuming params_to_accuracy is a dict where keys are tuples of hyperparameters and values are accuracies\n",
    "    hyperparams = list(zip(*params_to_accuracy.keys()))\n",
    "    accuracies = list(params_to_accuracy.values())\n",
    "\n",
    "    # Create subplots with shared y-axis\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(hyperparam_names), figsize=(15, 5), sharey=True)\n",
    "    if len(hyperparam_names) == 1:  # Handle the case where there's only one hyperparameter\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, hyperparam_values, hyperparam_name in zip(axes, hyperparams, hyperparam_names):\n",
    "        scatter = ax.scatter([str(x) for x in hyperparam_values], accuracies, c=accuracies, cmap='viridis', edgecolor='k')\n",
    "        ax.set_xlabel(hyperparam_name)\n",
    "        ax.set_title(f'{hyperparam_name} vs Accuracy')\n",
    "    \n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    cbar_ax = fig.add_axes([1.01, 0.15, 0.02, 0.7])  # Adjust the placement of the colorbar to be beside the plots\n",
    "    fig.colorbar(scatter, cax=cbar_ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d3e4c-d6e0-4aa8-9248-d43bc5a0b65c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparam_names = ['C', 'gamma', 'kernel']  # Update based on your hyperparameters\n",
    "scatter_plot_hyperparameters(params_to_accuracy, hyperparam_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed17675-1240-4c73-80a2-72e14515fdb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting values for plotting\n",
    "hyperparams = list(params_to_accuracy.keys())\n",
    "accuracies = list(params_to_accuracy.values())\n",
    "\n",
    "# Create a list of hyperparam strings for x-axis\n",
    "hyperparam_strings = [f\"C={hp[0]}, gamma={hp[1]}, kernel={hp[2]}\" for hp in hyperparams]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.barh(hyperparam_strings, accuracies, color='skyblue')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Hyperparameters')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c9dbc-6af9-4ee8-ae55-29a8daa61a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the hyperparameters with the best accuracy\n",
    "best_params = max(params_to_accuracy, key=params_to_accuracy.get)\n",
    "print(f\"Best hyperparameters were obtained with:\")\n",
    "print(f\"C={best_params[0]}, gamma={best_params[1]}, kernel={best_params[2]}\")\n",
    "print(f\"Resulting in an accuracy of: {params_to_accuracy[best_params]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b392f80-e7cc-42d2-9b51-475f06a6ea5b",
   "metadata": {},
   "source": [
    "Let's compare the speed to **sequential** execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf2d7f-9bcc-4b3b-9648-e7285d4b06d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for C in Cs:\n",
    "    for gamma in gamma_values:\n",
    "        for kernel in kernel_values:\n",
    "            # TODO: Queue the tasks\n",
    "            task_ref = training_task.remote(X_train, X_test, y_train, y_test, C=C, gamma=gamma, kernel=kernel)\n",
    "            ref_to_params[task_ref] = (C, gamma, kernel)\n",
    "            ray.wait([task_ref])\n",
    "            accuracy = ray.get(task_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe801c8e-3052-4333-881f-7c80526f0846",
   "metadata": {},
   "source": [
    "# Restart the notebook and replace the Address with the cluster IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126fc7f4-91a0-4e95-be93-e46bde7b41c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed9b3a38-cfb3-4986-9356-4c3c15c683eb",
   "metadata": {},
   "source": [
    "# Optional Exercise: Bigger dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78846e3-4acd-4ac8-850b-72cc2d8fc07b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fetch_and_prepare_mnist_from_csv(file_path, fraction=1.0):\n",
    "    # Ensure fraction is between 0 and 1\n",
    "    fraction = max(0.0, min(fraction, 1.0))\n",
    "    \n",
    "    # Load the dataset from the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract data and target (and scale the data between 0 and 1)\n",
    "    X = data.iloc[:, 1:].values / 255.0\n",
    "    y = data.iloc[:, 0].values\n",
    "    \n",
    "    # Take the desired fraction of the dataset\n",
    "    sample_size = int(len(X) * fraction)\n",
    "    X = X[:sample_size]\n",
    "    y = y[:sample_size]\n",
    "    \n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Example: Fetch 50% of the dataset\n",
    "# Make sure to provide the correct path to your CSV file in the function below\n",
    "X_train, X_test, y_train, y_test = fetch_and_prepare_mnist_from_csv('mnist_train.csv', fraction=0.25)\n",
    "print(\"Data fetched and prepared!\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e97b4-c34d-46b6-984e-b579cd95122b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3d411-7e2e-4d2a-ae18-4b76ada1f562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Label: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b068b870-f945-4ba9-9b9c-b09073143821",
   "metadata": {},
   "source": [
    "## Sending the dataset everytime is costly!\n",
    "Ray provide a way to send a refernce of an object to have a better performance, so let's put the datasets in a refernce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df0884-4e27-49a4-8edb-6bfb2b60446d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_ref, X_test_ref, y_train_ref, y_test_ref = ray.put(X_train), ray.put(X_test), ray.put(y_train), ray.put(y_test)\n",
    "\n",
    "ref_to_params: {str: tuple} = {}\n",
    "tasks = []\n",
    "for C in Cs:\n",
    "    for gamma in gamma_values:\n",
    "        for kernel in kernel_values:\n",
    "            # TODO: Queue the tasks\n",
    "            task_ref = training_task.remote(X_train_ref, X_test_ref, y_train_ref, y_test_ref, C=C, gamma=gamma, kernel=kernel)\n",
    "            ref_to_params[task_ref] = (C, gamma, kernel)\n",
    "            tasks.append(task_ref)\n",
    "        \n",
    "params_to_accuracy = {}        \n",
    "while tasks:\n",
    "    done_task_ref, tasks = ray.wait(tasks)\n",
    "    done_task_ref = done_task_ref[0]\n",
    "    accuracy = ray.get(done_task_ref)\n",
    "    \n",
    "    params = ref_to_params[done_task_ref]\n",
    "    params_to_accuracy[params] = accuracy\n",
    "    \n",
    "    # print(f\"Task with params {params} is completed, accuarcy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1345581-b493-4d5f-8c88-1cdde6f204a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparam_names = ['C', 'gamma', 'kernel']  # Update based on your hyperparameters\n",
    "scatter_plot_hyperparameters(params_to_accuracy, hyperparam_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc8012-7bf1-42a9-a84d-9c47f321a481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting values for plotting\n",
    "hyperparams = list(params_to_accuracy.keys())\n",
    "accuracies = list(params_to_accuracy.values())\n",
    "\n",
    "# Create a list of hyperparam strings for x-axis\n",
    "hyperparam_strings = [f\"C={hp[0]}, gamma={hp[1]}, kernel={hp[2]}\" for hp in hyperparams]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.barh(hyperparam_strings, accuracies, color='skyblue')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Hyperparameters')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e845db1-5369-4d93-9ff0-f38515124564",
   "metadata": {},
   "source": [
    "## MLP with MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2f86e-e825-493f-8815-89cd9fd166b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "@ray.remote\n",
    "def mlp_training_task(X_train, X_test, y_train, y_test, hidden_layer, activation, solver, alpha, learning_rate):\n",
    "    \n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer, activation=activation, \n",
    "        solver=solver, alpha=alpha, \n",
    "        learning_rate=learning_rate, max_iter=1000,  # added for convergence\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12acf996-f8b2-49fb-939b-c68be6902891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter values/ranges for tuning\n",
    "hidden_layer_sizes = [(50,), (100,), (50, 30)]\n",
    "activations = ['logistic', 'tanh', 'relu']\n",
    "# solvers = ['lbfgs', 'sgd', 'adam']\n",
    "alphas = [0.0001, 0.001, 0.01]\n",
    "learning_rates = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "# Loop over hyperparameters\n",
    "ref_to_params = {}\n",
    "tasks = []\n",
    "\n",
    "for hidden_layer in hidden_layer_sizes:\n",
    "    for activation in activations:\n",
    "        for alpha in alphas:\n",
    "            for lr in learning_rates:\n",
    "                task_ref = mlp_training_task.remote(X_train_ref, X_test_ref, y_train_ref, y_test_ref, hidden_layer, activation, 'sgd', alpha, lr)\n",
    "                ref_to_params[task_ref] = (hidden_layer, activation, alpha, lr)\n",
    "                tasks.append(task_ref)\n",
    "\n",
    "# Retrieve and print results\n",
    "params_to_accuracy = {}\n",
    "while tasks:\n",
    "    done_task_ref, tasks = ray.wait(tasks)\n",
    "    done_task_ref = done_task_ref[0]\n",
    "    accuracy = ray.get(done_task_ref)\n",
    "    \n",
    "    params = ref_to_params[done_task_ref]\n",
    "    params_to_accuracy[params] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cc3b61-97d1-4f9c-ae4d-81763fbe55b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparam_names = ['hidden_layer', 'activation', 'alpha', 'lr']  # Update based on your hyperparameters\n",
    "scatter_plot_hyperparameters(params_to_accuracy, hyperparam_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a282fc7-25a3-4c4a-b22e-29fb6e708e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting values for plotting\n",
    "hyperparams = list(params_to_accuracy.keys())\n",
    "accuracies = list(params_to_accuracy.values())\n",
    "\n",
    "# Create a list of hyperparam strings for x-axis\n",
    "# (hidden_layer, activation, solver, alpha, lr)\n",
    "hyperparam_strings = [f\"hidden_layer={hp[0]}, activation={hp[1]},\\nalpha={hp[2]}, lr={hp[3]}\" for hp in hyperparams]\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "plt.barh(hyperparam_strings, accuracies, color='skyblue')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Hyperparameters')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7948ec0-75d0-42f9-9347-82a6d7007f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the hyperparameters with the best accuracy\n",
    "best_params = max(params_to_accuracy, key=params_to_accuracy.get)\n",
    "print(f\"Best hyperparameters were obtained with:\")\n",
    "print(f\"C={best_params[0]}, gamma={best_params[1]}, kernel={best_params[2]}\")\n",
    "print(f\"Resulting in an accuracy of: {params_to_accuracy[best_params]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb60256-c249-4d77-a31f-7a49e0380403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
